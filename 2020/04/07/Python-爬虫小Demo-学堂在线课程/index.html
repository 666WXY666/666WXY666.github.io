<!DOCTYPE html><html><head hexo-theme="https://volantis.js.org/#2.6.6"><meta charset="utf-8"><meta name="renderer" content="webkit"><meta name="force-rendering" content="webkit"><meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1"><meta name="HandheldFriendly" content="True"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1"><title>Python 爬虫小Demo 学堂在线课程 - 苇名一心的博客</title><meta name="keywords" content="Python,爬虫,数据处理,学堂在线,课程"><meta name="description" content="本文是关于Python中的Spider的小Demo，通过Python的scrapy爬取京学堂在线课程的相关数据。"><link rel="alternate" href="/atom.xml" title="苇名一心的博客"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.13/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-waves@0.7.6/dist/waves.min.css"><link rel="shortcut icon" type="image/x-icon" href="https://cdn.jsdelivr.net/gh/666WXY666/cdn/img/favicon/favicon.ico"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/aplayer@1.10/dist/APlayer.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/666WXY666/cdn@8.8/css/style.css"><script>function setLoadingBarProgress(e){document.getElementById("loading-bar").style.width=e+"%"}</script><script>setTimeout(function() {
	  let script = document.createElement('script');
	  script.src = "https://www.googletagmanager.com/gtag/js?id=UA-162450234-2";
	  script.defer=true;
	  document.body.appendChild(script);
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-162450234-2');
	}, 5000);</script><script>var _hmt=_hmt||[];setTimeout(function(){var e=document.createElement("script");e.src="https://hm.baidu.com/hm.js?93c49980dcbfb8920e167f85129d6917",e.defer=!0;var t=document.getElementsByTagName("script")[0];t.parentNode.insertBefore(e,t)},5e3)</script></head><body><div id="loading-bar-wrapper"><div id="loading-bar"></div></div><header class="l_header shadow blur"><div class="container"><div class="wrapper"><div class="nav-sub"><p class="title"></p><ul class="switcher nav-list-h"><li><a class="s-comment fas fa-comments fa-fw" target="_self" href="javascript:void(0)"></a></li><li><a class="s-toc fas fa-list fa-fw" target="_self" href="javascript:void(0)"></a></li></ul></div><div class="nav-main"><a class="title flat-box" target="_self" href="/"><img class="logo" src="https://cdn.jsdelivr.net/gh/666WXY666/cdn/img/placeholder/large.svg" data-original="https://cdn.jsdelivr.net/gh/666WXY666/cdn@master/img/logo/logo-round.png"></a><div class="menu navigation"><ul class="nav-list-h"><li><a class="flat-box" href="/" id="home"><i class="fas fa-rss fa-fw"></i>博客</a></li><li><a class="flat-box" href="/categories/" id="categories"><i class="fas fa-folder-open fa-fw"></i>分类</a></li><li><a class="flat-box" href="/tags/" id="tags"><i class="fas fa-tags fa-fw"></i>标签</a></li><li><a class="flat-box" href="/archives/" id="archives"><i class="fas fa-archive fa-fw"></i>归档</a></li><li><a class="flat-box" href="/friends/" id="friends"><i class="fas fa-link fa-fw"></i>友链</a></li><li><a class="flat-box" href="/about/" id="about"><i class="fas fa-info-circle fa-fw"></i>关于</a></li><li><a class="flat-box"><i class="fas fa-ellipsis-v fa-fw"></i>更多</a><ul class="list-v"><li><a class="flat-box">有疑问？</a><ul class="list-v"><li><a class="flat-box" href="/faqs/" id="faqs"><i class="fas fa-question-circle fa-fw"></i>FAQ</a></li><li><a class="flat-box" href="https://github.com/666WXY666/" id="https:githubcom666WXY666" rel="external nofollow noopener noreferrer" target="_blank"><i class="fab fa-github fa-fw"></i>我的Github主页</a></li><li><a class="flat-box" href="https://gitee.com/wxy_666" id="https:giteecomwxy_666" rel="external nofollow noopener noreferrer" target="_blank"><i class="fab fa-git-alt fa-fw"></i>我的Gitee主页</a></li><li><a class="flat-box" href="https://github.com/666WXY666/666WXY666.github.io/" id="https:githubcom666WXY666666WXY666githubio" rel="external nofollow noopener noreferrer" target="_blank"><i class="fas fa-code fa-fw"></i>本站源码</a></li><li><a class="flat-box" href="https://github.com/666WXY666/666WXY666.github.io/issues/" id="https:githubcom666WXY666666WXY666githubioissues" rel="external nofollow noopener noreferrer" target="_blank"><i class="fas fa-question fa-fw"></i>向我提问</a></li></ul></li><hr><li><a class="flat-box"><i class="fas fa-compact-disc fa-fw music fa-fw music"></i>背景音乐</a><ul class="list-v"><li><div class="aplayer-container"><meting-js theme="#1BCDFC" autoplay volume="0.7" loop order="list" fixed="false" list-max-height="340px" server="tencent" type="playlist" id="1930654125" list-folded="true"></meting-js></div></li></ul></li><li></li></ul></li></ul></div><div class="m_search"><form name="searchform" class="form u-search-form"><i class="icon fas fa-search fa-fw"></i> <input type="text" class="input u-search-input" placeholder="Search..."></form></div><ul class="switcher nav-list-h"><li><a class="s-search fas fa-search fa-fw" target="_self" href="javascript:void(0)"></a></li><li><a class="s-menu fas fa-bars fa-fw" target="_self" href="javascript:void(0)"></a><ul class="menu-phone list-v navigation white-box"><li><a class="flat-box" href="/" id="home"><i class="fas fa-rss fa-fw"></i>博客</a></li><li><a class="flat-box" href="/categories/" id="categories"><i class="fas fa-folder-open fa-fw"></i>分类</a></li><li><a class="flat-box" href="/tags/" id="tags"><i class="fas fa-tags fa-fw"></i>标签</a></li><li><a class="flat-box" href="/archives/" id="archives"><i class="fas fa-archive fa-fw"></i>归档</a></li><li><a class="flat-box" href="/friends/" id="friends"><i class="fas fa-link fa-fw"></i>友链</a></li><li><a class="flat-box" href="/about/" id="about"><i class="fas fa-info-circle fa-fw"></i>关于</a></li><li><a class="flat-box"><i class="fas fa-ellipsis-v fa-fw"></i>更多</a><ul class="list-v"><li><a class="flat-box">有疑问？</a><ul class="list-v"><li><a class="flat-box" href="/faqs/" id="faqs"><i class="fas fa-question-circle fa-fw"></i>FAQ</a></li><li><a class="flat-box" href="https://github.com/666WXY666/" id="https:githubcom666WXY666" rel="external nofollow noopener noreferrer" target="_blank"><i class="fab fa-github fa-fw"></i>我的Github主页</a></li><li><a class="flat-box" href="https://gitee.com/wxy_666" id="https:giteecomwxy_666" rel="external nofollow noopener noreferrer" target="_blank"><i class="fab fa-git-alt fa-fw"></i>我的Gitee主页</a></li><li><a class="flat-box" href="https://github.com/666WXY666/666WXY666.github.io/" id="https:githubcom666WXY666666WXY666githubio" rel="external nofollow noopener noreferrer" target="_blank"><i class="fas fa-code fa-fw"></i>本站源码</a></li><li><a class="flat-box" href="https://github.com/666WXY666/666WXY666.github.io/issues/" id="https:githubcom666WXY666666WXY666githubioissues" rel="external nofollow noopener noreferrer" target="_blank"><i class="fas fa-question fa-fw"></i>向我提问</a></li></ul></li><hr></ul></li></ul></li></ul></div></div></div></header><script>setLoadingBarProgress(40)</script><div class="l_body nocover"><div class="body-wrapper"><div class="l_main"><article id="post" class="post white-box reveal shadow article-type-post" itemscope itemprop="blogPost"><section class="meta"><div class="meta" id="header-meta"><h1 class="title"><a href="/2020/04/07/Python-%E7%88%AC%E8%99%AB%E5%B0%8FDemo-%E5%AD%A6%E5%A0%82%E5%9C%A8%E7%BA%BF%E8%AF%BE%E7%A8%8B/">Python 爬虫小Demo 学堂在线课程</a></h1><div class="new-meta-box"><div class="new-meta-item author"><a href="https://666wxy666.github.io/" rel="nofollow"><img src="https://cdn.jsdelivr.net/gh/666WXY666/cdn/img/placeholder/large.svg" data-original="https://cdn.jsdelivr.net/gh/666WXY666/cdn@master/img/avatar/avatar.jpg"><p>苇名一心</p></a></div><div class="new-meta-item category"><a href="/categories/Python/%E7%88%AC%E8%99%AB/" rel="nofollow"><i class="fas fa-folder-open fa-fw" aria-hidden="true"></i><p>Python/爬虫</p></a></div><div class="new-meta-item date"><a class="notlink"><i class="fas fa-calendar-alt fa-fw" aria-hidden="true"></i><p>发布于：2020年4月7日</p></a></div><div class="new-meta-item wordcount"><a class="notlink"><i class="fas fa-keyboard fa-fw" aria-hidden="true"></i><p>字数：1.5k字</p></a></div><div class="new-meta-item readtime"><a class="notlink"><i class="fas fa-hourglass-half fa-fw" aria-hidden="true"></i><p>时长：6分钟</p></a></div><div class="new-meta-item browse valine"><a class="notlink"><i class="fas fa-eye fa-fw" aria-hidden="true"></i> <span id="/2020/04/07/Python-%E7%88%AC%E8%99%AB%E5%B0%8FDemo-%E5%AD%A6%E5%A0%82%E5%9C%A8%E7%BA%BF%E8%AF%BE%E7%A8%8B/" class="leancloud_visitors" data-flag-title="Python 爬虫小Demo 学堂在线课程"><p><span class="leancloud-visitors-count"></span></p></span></a></div></div><hr></div></section><section class="article typo"><div class="article-entry" itemprop="articleBody"><p><strong>本文是关于Python中的Spider的小Demo，通过Python的scrapy爬取京学堂在线课程的相关数据。</strong></p><a id="more"></a><h2 id="一、编译环境："><a href="#一、编译环境：" class="headerlink" title="一、编译环境："></a>一、编译环境：</h2><p>PyCharm 2019.3.4 (Professional Edition)</p><p>Build #PY-193.6911.25, built on March 18, 2020</p><p>Runtime version: 11.0.6+8-b520.43 amd64</p><p>VM: OpenJDK 64-Bit Server VM by JetBrains s.r.o</p><p>Windows 10 10.0</p><p>GC: ParNew, ConcurrentMarkSweep</p><p>Memory: 725M</p><p>Cores: 8</p><p>Registry: ide.balloon.shadow.size=0</p><p>Non-Bundled Plugins:</p><p>GrepConsole,Statistic,cn.yiiguxing.plugin.translate,com.chrisrm.idea.MaterialThemeUI,com.notime.intellijPlugin.backgroundImagePlus,com.wakatime.intellij.plugin,izhangzhihao.rainbow.brackets,mobi.hsz.idea.gitignore, net.vektah.codeglance, org.intellij.gitee</p><p>Python Version：3.7（Anaconda3）</p><p>Package：</p><p>scrapy==2.0.1</p><h2 id="二、详细步骤"><a href="#二、详细步骤" class="headerlink" title="二、详细步骤"></a>二、详细步骤</h2><h3 id="①准备工作"><a href="#①准备工作" class="headerlink" title="①准备工作"></a>①准备工作</h3><ol><li>在Pycharm中新建一个Pure Python项目（记得要按照一中的要求配好Python环境）。</li></ol><img src="https://cdn.jsdelivr.net/gh/666WXY666/cdn/img/placeholder/large.svg" data-original="https://gitee.com/wxy_666/images/raw/master/20200407214757.jpg" alt="2020-04-07_214715" style="zoom:67%"><ol start="2"><li>打开Pycharm的下方的终端（Terminal），当然这些也可以在系统终端里操作，不过可能需要的步骤多一些，还是直接在Pycharm里方便一些。</li></ol><p><img src="https://cdn.jsdelivr.net/gh/666WXY666/cdn/img/placeholder/large.svg" data-original="https://gitee.com/wxy_666/images/raw/master/20200408164806.png" alt="2020-04-08_164744"></p><ol start="3"><li><p>在终端里输入</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy startproject myScrapy</span><br></pre></td></tr></table></figure><p>本来是可以在我们刚刚创建的项目里新建一个名为“myScrapy”的scrapy项目的，但是不知道为什么竟然报错了：</p><p><img src="https://cdn.jsdelivr.net/gh/666WXY666/cdn/img/placeholder/large.svg" data-original="https://gitee.com/wxy_666/images/raw/master/20200408190345.png" alt="2020-04-08_190330"></p><p>这是什么奇奇怪怪的错误，我都没有“d:\bld\scrapy_1584555997548_h_env\python.exe”这个目录，经过查找相关问题的资料，问题可能是出在Python环境上，因为我上一次新建项目时并没有报错，这一次我直接用的上一个项目的环境，网上还有一种说法是Scrapy的bug，详见</p><p><a href="https://github.com/scrapy/scrapy/issues/4289" target="_blank" rel="external nofollow noopener noreferrer">Fatal error launching scrapy&gt;1.6.0 from Anaconda Prompt</a></p><p><a href="https://github.com/conda-forge/scrapy-feedstock/issues/37" target="_blank" rel="external nofollow noopener noreferrer">Issue with conda-forge scrapy&gt;1.6.0 on Windows</a></p><p>目前找到了两种解决方案：</p><ol><li><p>把python环境复制到报错的那个目录（d:\bld\scrapy_1584555997548_h_env\python.exe），然后在创建scrapy项目，但这个解决方法有点愚蠢，就没有采用。</p></li><li><p>在scrapy命令前面添加“python -m”选项：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python -m scrapy startproject myScrapy</span><br></pre></td></tr></table></figure><p>就可以正常创建了。</p><p>关于Python的-m选项，官方给出的解释是“run library module as a script”，简单来说就是将库中的Python模块当作脚本去运行。</p><p>特别感谢简书的大佬<a href="https://www.jianshu.com/p/323fc9a1d7d2" target="_blank" rel="external nofollow noopener noreferrer">ccw1078</a>提供的解释，很清晰明了，有兴趣的可以去瞅一下，因为和本文的主题爬虫没啥关系，在这里就不赘述了。</p></li></ol></li></ol><ol start="4"><li><p>出现这些提示就代表创建成功了。</p><p><img src="https://cdn.jsdelivr.net/gh/666WXY666/cdn/img/placeholder/large.svg" data-original="https://gitee.com/wxy_666/images/raw/master/20200408192211.jpg" alt="2020-04-08_192151"></p><p>然后在spiders文件里新建一个spider.py文件，用于写爬虫。</p></li><li><p>我们来看一下目前scrapy项目的目录结构。</p><img src="https://cdn.jsdelivr.net/gh/666WXY666/cdn/img/placeholder/large.svg" data-original="https://gitee.com/wxy_666/images/raw/master/20200408203358.jpg" alt="2020-04-08_203310" style="zoom:67%"><p>__init__.py：pycharm生成的文件，简化导入语句用的，可以忽略，没啥用，建议删了，留着可能会出问题。</p><p>spiders：存放你Spider爬虫源文件</p><p>​ spider.py：代码主要在这里写。</p><p>items.py：数据容器。</p><p>middlewares.py：Downloader Middlewares(下载器中间件)和Spider Middlewares(蜘蛛中间件)实现的地方。</p><p>pipelines.py：项目管道文件，相当于数据中转站。实现数据的清洗，储存，验证。</p><p>settings.py：scrapy的全局配置。</p><p>scrapy.cfg：配置文件。</p><p>scrapy已经帮我们把大体框架写好了，我们主要要修改的文件是spider.py，items.py，pipelines.py，settings.py。</p></li><li><p>这是爬虫spider的基本工作方式，想要深入了解的可以去网上查找资料。</p></li></ol><img src="https://cdn.jsdelivr.net/gh/666WXY666/cdn/img/placeholder/large.svg" data-original="https://gitee.com/wxy_666/images/raw/master/20200408201638.png" alt="scrapy" style="zoom:33%"><h3 id="②开始写代码"><a href="#②开始写代码" class="headerlink" title="②开始写代码"></a>②开始写代码</h3><ol><li><p>先来写items.py。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyscrapyItem</span><span class="params">(scrapy.Item)</span>:</span></span><br><span class="line">    <span class="comment"># define the fields for your item here like:</span></span><br><span class="line">    <span class="comment"># name = scrapy.Field()</span></span><br><span class="line">    school = scrapy.Field()</span><br><span class="line">    num = scrapy.Field()</span><br><span class="line">    <span class="keyword">pass</span></span><br></pre></td></tr></table></figure></li><li><p>再来搞settings.py，这个只需要找到这个注释掉的语句，把#去掉就OK了，就像这样：</p><img src="https://cdn.jsdelivr.net/gh/666WXY666/cdn/img/placeholder/large.svg" data-original="https://gitee.com/wxy_666/images/raw/master/20200408210722.jpg" alt="2020-04-08_210710" style="zoom:67%"></li><li><p>pipelines.py就很好写了，基本可以当模板来用。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyscrapyPipeline</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">open_spider</span><span class="params">(self, spider)</span>:</span></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            <span class="comment"># 这个就是爬虫生成的文件，可以支持好多种格式，这里使用的是json文件</span></span><br><span class="line">            self.file = open(<span class="string">'MyData.json'</span>, <span class="string">'w'</span>, encoding=<span class="string">"utf-8"</span>)</span><br><span class="line">        <span class="keyword">except</span> Exception <span class="keyword">as</span> err:</span><br><span class="line">            print(err)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_item</span><span class="params">(self, item, spider)</span>:</span></span><br><span class="line">        dict_item = dict(item)</span><br><span class="line">        json_str = json.dumps(dict_item, ensure_ascii=<span class="literal">False</span>) + <span class="string">"\n"</span></span><br><span class="line">        self.file.write(json_str)</span><br><span class="line">        <span class="keyword">return</span> item</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">close_spider</span><span class="params">(self, spider)</span>:</span></span><br><span class="line">        self.file.close()</span><br></pre></td></tr></table></figure></li><li><p>spider.py是我们主要写的核心部分。这里需要一些html的xpath相关知识来对项进行定位，可以自行查找相关资料。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">@Copyright: Copyright (c) 2020 苇名一心 All Rights Reserved.</span></span><br><span class="line"><span class="string">@Project: xuetangzaixian</span></span><br><span class="line"><span class="string">@Description: </span></span><br><span class="line"><span class="string">@Version: </span></span><br><span class="line"><span class="string">@Author: 苇名一心</span></span><br><span class="line"><span class="string">@Date: 2020-04-08 20:31</span></span><br><span class="line"><span class="string">@LastEditors: 苇名一心</span></span><br><span class="line"><span class="string">@LastEditTime: 2020-04-08 20:31</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">from</span> myScrapy.myScrapy.items <span class="keyword">import</span> MyscrapyItem</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">mySpider</span><span class="params">(scrapy.spiders.Spider)</span>:</span></span><br><span class="line">    <span class="comment"># spider的名字</span></span><br><span class="line">    name = <span class="string">"xuetang"</span></span><br><span class="line">    <span class="comment"># 限制spider爬取的域名</span></span><br><span class="line">    allowed_domains = [<span class="string">"www.xuetangx.com/"</span>]</span><br><span class="line">	<span class="comment"># 爬虫要爬取的网页，是一个列表，按顺序爬取</span></span><br><span class="line">    start_urls = [<span class="string">"http://www.xuetangx.com/partners"</span>]</span><br><span class="line">	<span class="comment"># 这是一种方式，可以爬取网页中所有的项</span></span><br><span class="line">    <span class="comment"># def parse(self, response):</span></span><br><span class="line">    <span class="comment">#     item = MyscrapyItem()</span></span><br><span class="line">    <span class="comment">#     for each in response.xpath("/html/body/article[1]/section/ul/*"):</span></span><br><span class="line">    <span class="comment">#         item['school'] = each.xpath("a/div[2]/h3/text()").extract()</span></span><br><span class="line">    <span class="comment">#         item['num'] = each.xpath("a/div[2]/p[1]/text()").extract()</span></span><br><span class="line">    <span class="comment">#         if item['num']:</span></span><br><span class="line">    <span class="comment">#             item['num'] = re.findall(r'\d+', item['num'][0])</span></span><br><span class="line">    <span class="comment">#         if item['school'] and item['num']:</span></span><br><span class="line">    <span class="comment">#             yield (item)</span></span><br><span class="line">    <span class="comment"># 这是第二种方式，使用for循环，制定爬取项的数目</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        item = MyscrapyItem()</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>, <span class="number">144</span>):</span><br><span class="line">            item[<span class="string">'school'</span>] = response.xpath \</span><br><span class="line">                (<span class="string">"/html/body/article[1]/section/ul/li[&#123;&#125;]/a/div[2]/h3/text()"</span>.format(i)).extract()</span><br><span class="line">            item[<span class="string">'num'</span>] = response.xpath \</span><br><span class="line">                (<span class="string">"/html/body/article[1]/section/ul/li[&#123;&#125;]/a/div[2]/p[1]/text()"</span>.format(i)).extract()</span><br><span class="line">            <span class="comment"># 判断爬取的项目是否为空，把非空的项目提交</span></span><br><span class="line">            <span class="keyword">if</span> item[<span class="string">'school'</span>] <span class="keyword">and</span> item[<span class="string">'num'</span>]:</span><br><span class="line">                <span class="keyword">yield</span> (item)</span><br></pre></td></tr></table></figure></li></ol><h3 id="③可以开始运行啦"><a href="#③可以开始运行啦" class="headerlink" title="③可以开始运行啦"></a>③可以开始运行啦</h3><ol><li><p>在运行前要先在项目根目录下建立一个begin.py文件来控制scrapy爬虫的运行。</p><img src="https://cdn.jsdelivr.net/gh/666WXY666/cdn/img/placeholder/large.svg" data-original="https://gitee.com/wxy_666/images/raw/master/20200408212615.jpg" alt="2020-04-08_212604" style="zoom:80%"><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> scrapy <span class="keyword">import</span> cmdline</span><br><span class="line"><span class="comment"># "xuetang"是我们上面spider.py中定义的爬虫名</span></span><br><span class="line">cmdline.execute(<span class="string">"scrapy crawl xuetang"</span>.split())</span><br></pre></td></tr></table></figure></li><li><p>最终的项目结构（__init__.py没啥用，删了）：</p><img src="https://cdn.jsdelivr.net/gh/666WXY666/cdn/img/placeholder/large.svg" data-original="https://gitee.com/wxy_666/images/raw/master/20200408212844.jpg" alt="2020-04-08_212834" style="zoom:67%"></li><li><p>运行begin.py就可以开始爬虫了。</p><img src="https://cdn.jsdelivr.net/gh/666WXY666/cdn/img/placeholder/large.svg" data-original="https://gitee.com/wxy_666/images/raw/master/20200408212955.jpg" alt="2020-04-08_212946" style="zoom:67%"><p>出现这些提示就表示成功了，运行完毕后会发现项目根目录出现了我们在pipelines.py中设置好的MyData.json。</p><img src="https://cdn.jsdelivr.net/gh/666WXY666/cdn/img/placeholder/large.svg" data-original="https://gitee.com/wxy_666/images/raw/master/20200408222346.jpg" alt="2020-04-08_222333" style="zoom:67%"></li><li><p>打开MyData.json看一下，Perfect！</p><img src="https://cdn.jsdelivr.net/gh/666WXY666/cdn/img/placeholder/large.svg" data-original="https://gitee.com/wxy_666/images/raw/master/20200408222427.jpg" alt="2020-04-08_222417" style="zoom:67%"><p>有了这个json文件，我们就可以利用Python的pandas、numpy等工具进行各种处理，然后用matplotlib等模块进行画图了。</p></li></ol><h2 id="三、总结"><a href="#三、总结" class="headerlink" title="三、总结"></a>三、总结</h2><p>本文只是对Python的scrapy爬虫进行了简单的介绍和用一个小Demo讲述了如何使用scrapy爬取网页数据，希望对你有所帮助。</p><div class="article_footer"><section class="widget copyright desktop mobile"><div class="content"><blockquote><p>本文为博主「苇名一心」的原创文章</p><p>内容遵循 署名-非商业性使用-相同方式共享 4.0 国际 (CC BY-NC-SA 4.0) 协议</p><p>本文永久链接是：<a href="https://666wxy666.github.io/2020/04/07/Python-%E7%88%AC%E8%99%AB%E5%B0%8FDemo-%E5%AD%A6%E5%A0%82%E5%9C%A8%E7%BA%BF%E8%AF%BE%E7%A8%8B/">https://666wxy666.github.io/2020/04/07/Python-%E7%88%AC%E8%99%AB%E5%B0%8FDemo-%E5%AD%A6%E5%A0%82%E5%9C%A8%E7%BA%BF%E8%AF%BE%E7%A8%8B/</a></p><p>转载请附上原文出处链接及本声明</p></blockquote></div></section><section class="widget qrcode desktop mobile"><div class="content article-entry"><div class="fancybox"><img src="https://cdn.jsdelivr.net/gh/666WXY666/cdn/img/placeholder/large.svg" data-original="https://cdn.jsdelivr.net/gh/666WXY666/cdn@master/img/qrcode/weixin.jpg" height="64px"></div><div class="fancybox"><img src="https://cdn.jsdelivr.net/gh/666WXY666/cdn/img/placeholder/large.svg" data-original="https://cdn.jsdelivr.net/gh/666WXY666/cdn@master/img/qrcode/alipay.jpg" height="64px"></div></div></section></div></div><section class="meta" id="footer-meta"><div class="new-meta-box"><div class="new-meta-item date" itemprop="dateUpdated" datetime="2020-05-18T20:22:07+08:00"><a class="notlink"><i class="fas fa-edit fa-fw" aria-hidden="true"></i><p>更新于：2020年5月18日</p></a></div><div class="new-meta-item meta-tags"><a class="tag" href="/tags/Python/" rel="nofollow"><i class="fas fa-hashtag fa-fw" aria-hidden="true"></i><p>Python</p></a></div><div class="new-meta-item meta-tags"><a class="tag" href="/tags/%E7%88%AC%E8%99%AB/" rel="nofollow"><i class="fas fa-hashtag fa-fw" aria-hidden="true"></i><p>爬虫</p></a></div><div class="new-meta-item meta-tags"><a class="tag" href="/tags/%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86/" rel="nofollow"><i class="fas fa-hashtag fa-fw" aria-hidden="true"></i><p>数据处理</p></a></div><div class="new-meta-item meta-tags"><a class="tag" href="/tags/%E5%AD%A6%E5%A0%82%E5%9C%A8%E7%BA%BF/" rel="nofollow"><i class="fas fa-hashtag fa-fw" aria-hidden="true"></i><p>学堂在线</p></a></div><div class="new-meta-item meta-tags"><a class="tag" href="/tags/%E8%AF%BE%E7%A8%8B/" rel="nofollow"><i class="fas fa-hashtag fa-fw" aria-hidden="true"></i><p>课程</p></a></div><div class="new-meta-item wordcount"><a class="notlink"><i class="fas fa-keyboard fa-fw" aria-hidden="true"></i><p>字数：1.5k字</p></a></div><div class="new-meta-item readtime"><a class="notlink"><i class="fas fa-hourglass-half fa-fw" aria-hidden="true"></i><p>时长：6分钟</p></a></div><div class="new-meta-item share -mob-share-list"><div class="-mob-share-list share-body"><a class="-mob-share-qq" rel="external nofollow noopener noreferrer" href="http://connect.qq.com/widget/shareqq/index.html?url=https://666wxy666.github.io/2020/04/07/Python-%E7%88%AC%E8%99%AB%E5%B0%8FDemo-%E5%AD%A6%E5%A0%82%E5%9C%A8%E7%BA%BF%E8%AF%BE%E7%A8%8B/&title=Python 爬虫小Demo 学堂在线课程 - 苇名一心的博客&summary=本文是关于Python中的Spider的小Demo，通过Python的scrapy爬取京学堂在线课程的相关数据。" target="_blank"><img src="https://cdn.jsdelivr.net/gh/666WXY666/cdn/img/placeholder/large.svg" data-original="https://cdn.jsdelivr.net/gh/666WXY666/cdn@master/img/logo/128/qq.png"> </a><a class="-mob-share-qzone" rel="external nofollow noopener noreferrer" href="https://sns.qzone.qq.com/cgi-bin/qzshare/cgi_qzshare_onekey?url=https://666wxy666.github.io/2020/04/07/Python-%E7%88%AC%E8%99%AB%E5%B0%8FDemo-%E5%AD%A6%E5%A0%82%E5%9C%A8%E7%BA%BF%E8%AF%BE%E7%A8%8B/&title=Python 爬虫小Demo 学堂在线课程 - 苇名一心的博客&summary=本文是关于Python中的Spider的小Demo，通过Python的scrapy爬取京学堂在线课程的相关数据。" target="_blank"><img src="https://cdn.jsdelivr.net/gh/666WXY666/cdn/img/placeholder/large.svg" data-original="https://cdn.jsdelivr.net/gh/666WXY666/cdn@master/img/logo/128/qzone.png"> </a><a class="-mob-share-weibo" rel="external nofollow noopener noreferrer" href="http://service.weibo.com/share/share.php?url=https://666wxy666.github.io/2020/04/07/Python-%E7%88%AC%E8%99%AB%E5%B0%8FDemo-%E5%AD%A6%E5%A0%82%E5%9C%A8%E7%BA%BF%E8%AF%BE%E7%A8%8B/&title=Python 爬虫小Demo 学堂在线课程 - 苇名一心的博客&summary=本文是关于Python中的Spider的小Demo，通过Python的scrapy爬取京学堂在线课程的相关数据。" target="_blank"><img src="https://cdn.jsdelivr.net/gh/666WXY666/cdn/img/placeholder/large.svg" data-original="https://cdn.jsdelivr.net/gh/666WXY666/cdn@master/img/logo/128/weibo.png"></a></div></div></div></section><div class="prev-next"><a class="prev" href="/2020/04/28/Linux-MOOC%E4%B9%A0%E9%A2%98-1~5%E7%AB%A0/"><p class="title"><i class="fas fa-chevron-left" aria-hidden="true"></i>Linux MOOC习题 1~5章</p><p class="content">自己随便整理了一下在学习Linux网课时遇到的一些习题，易错点之类的。废话不多说，直接开始：PS：第一章是课程介绍。二、开始使用Linux和文本文件的处理第1题其实是很基础的问题，早期的终端一般...</p></a><a class="next" href="/2020/03/31/Linux-%E4%B8%8A%E6%9C%BA%E5%AE%9E%E6%88%981-%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/"><p class="title">Linux 上机实战1 正则表达式<i class="fas fa-chevron-right" aria-hidden="true"></i></p><p class="content">本文是关于Linux中的文本处理三剑客（grep，sed，awk），以及正则表达式应用的一个样例，获取北京某时刻PM2.5的数据，然后进行处理，输出到csv文件中，并画图表展示。一、题目要求：​...</p></a></div></section></article><article class="post white-box reveal comments shadow"><section class="article typo"><p ct><i class="fas fa-comments"></i> 评论</p><section id="comments"><div id="valine_container" class="valine_thread"><i class="fas fa-cog fa-spin fa-fw fa-2x"></i></div></section></section></article><script>window.subData={title:"Python 爬虫小Demo 学堂在线课程",tools:!0}</script></div><aside class="l_side"><section class="widget toc-wrapper shadow desktop mobile"><header><i class="fas fa-list fa-fw" aria-hidden="true"></i><span class="name">本文目录</span></header><div class="content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#一、编译环境："><span class="toc-text">一、编译环境：</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#二、详细步骤"><span class="toc-text">二、详细步骤</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#①准备工作"><span class="toc-text">①准备工作</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#②开始写代码"><span class="toc-text">②开始写代码</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#③可以开始运行啦"><span class="toc-text">③可以开始运行啦</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#三、总结"><span class="toc-text">三、总结</span></a></li></ol></div></section><section class="widget related_posts shadow desktop mobile"><header><i class="fas fa-bookmark fa-fw" aria-hidden="true"></i><span class="name">相关文章</span></header><div class="content"></div></section></aside><footer class="clearfix"><br><br><div class="aplayer-container"><meting-js theme="#1BCDFC" autoplay volume="0.7" loop order="list" fixed="false" list-max-height="340px" server="tencent" type="playlist" id="1930654125" list-folded="true"></meting-js></div><br><div class="social-wrapper"><a href="/atom.xml" class="social fas fa-rss flat-btn" target="_blank" rel="external nofollow noopener noreferrer"></a> <a href="mailto:1293739194@qq.com" class="social fas fa-envelope flat-btn" target="_blank" rel="external nofollow noopener noreferrer"></a> <a href="https://github.com/666WXY666/" class="social fab fa-github flat-btn" target="_blank" rel="external nofollow noopener noreferrer"></a> <a href="https://gitee.com/wxy_666" class="social fab fa-git-alt flat-btn" target="_blank" rel="external nofollow noopener noreferrer"></a> <a href="https://space.bilibili.com/7429248" class="social fas fa-bold flat-btn" target="_blank" rel="external nofollow noopener noreferrer"></a> <a href="https://www.zhihu.com/people/666wxy666" class="social fab fa-zhihu flat-btn" target="_blank" rel="external nofollow noopener noreferrer"></a> <a href="https://music.163.com/#/user/home?id=74040689" class="social fas fa-headphones-alt flat-btn" target="_blank" rel="external nofollow noopener noreferrer"></a></div><div><p>博客内容遵循 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" target="_blank" rel="external nofollow noopener noreferrer">署名-非商业性使用-相同方式共享 4.0 国际 (CC BY-NC-SA 4.0) 协议</a></p></div><div class="copyright"><p><a href="https://666wxy666.github.io/">Copyright © 2020-2020 苇名一心</a></p></div><br><i class="fas fa-clock"></i> <span id="timeDate">载入天数...</span><span id="times">载入时分秒...</span><script>var now=new Date;function createtime(){var n=new Date("02/10/2020 17:38:00");now.setTime(now.getTime()+250),days=(now-n)/1e3/60/60/24,dnum=Math.floor(days),hours=(now-n)/1e3/60/60-24*dnum,hnum=Math.floor(hours),1==String(hnum).length&&(hnum="0"+hnum),minutes=(now-n)/1e3/60-1440*dnum-60*hnum,mnum=Math.floor(minutes),1==String(mnum).length&&(mnum="0"+mnum),seconds=(now-n)/1e3-86400*dnum-3600*hnum-60*mnum,snum=Math.round(seconds),1==String(snum).length&&(snum="0"+snum),document.getElementById("timeDate").innerHTML="本站已成功存活了 "+dnum+" 天 ",document.getElementById("times").innerHTML=hnum+" 小时 "+mnum+" 分 "+snum+" 秒"}setInterval("createtime()",250)</script><br><i class="fas fa-user"></i> <span id="busuanzi_container_site_uv">总访客数：<span id="busuanzi_value_site_uv"></span> 人 | </span><i class="fas fa-eye"></i> <span id="busuanzi_container_site_pv">总阅读量：<span id="busuanzi_value_site_pv"></span> 次 | </span><i class="fas fa-chart-area"></i> <span class="post-count">字数统计：33.2k 字</span></footer><script>setLoadingBarProgress(80)</script><script>setLoadingBarProgress(60)</script></div><a class="s-top fas fa-arrow-up fa-fw" href="javascript:void(0)"></a></div><script src="https://cdn.jsdelivr.net/npm/jquery@3.4/dist/jquery.min.js"></script><script>var SEARCH_SERVICE="hexo",ROOT="/";ROOT.endsWith("/")||(ROOT+="/")</script><script async src="https://cdn.jsdelivr.net/gh/xaoxuu/cdn-volantis@2/js/instant_page.js" type="module" defer integrity="sha384-OeDn4XE77tdHo8pGtE1apMPmAipjoxUQ++eeJa6EtJCfHlvijigWiJpD7VDPWXV1"></script><script src="https://cdn.jsdelivr.net/npm/scrollreveal@4.0.6/dist/scrollreveal.min.js"></script><script type="text/javascript">$(function(){ScrollReveal().reveal(".l_main .reveal",{distance:"8px",duration:"800",interval:"100",scale:"1"})})</script><script src="https://cdn.jsdelivr.net/npm/node-waves@0.7.6/dist/waves.min.js"></script><script type="text/javascript">$(function(){Waves.attach(".flat-btn",["waves-button"]),Waves.attach(".float-btn",["waves-button","waves-float"]),Waves.attach(".float-btn-light",["waves-button","waves-float","waves-light"]),Waves.attach(".flat-box",["waves-block"]),Waves.attach(".float-box",["waves-block","waves-float"]),Waves.attach(".waves-image"),Waves.init()})</script><script defer src="https://cdn.jsdelivr.net/gh/xaoxuu/cdn-busuanzi@2.3/js/busuanzi.pure.mini.js"></script><script src="https://cdn.jsdelivr.net/npm/jquery-backstretch@2.1.18/jquery.backstretch.min.js"></script><script type="text/javascript">$(function(){var t=["https://cdn.jsdelivr.net/gh/666WXY666/cdn/img/wallpaper/abstract/41F215B9-261F-48B4-80B5-4E86E165259E.jpeg","https://cdn.jsdelivr.net/gh/666WXY666/cdn/img/wallpaper/abstract/BBC19066-E176-47C2-9D22-48C81EE5DF6B.jpeg","https://cdn.jsdelivr.net/gh/666WXY666/cdn/img/wallpaper/abstract/35F12181-F0E9-45BD-B134-37E4B4A660CF.jpeg","https://cdn.jsdelivr.net/gh/666WXY666/cdn/img/wallpaper/abstract/B18FCBB3-67FD-48CC-B4F3-457BA145F17A.jpeg","https://cdn.jsdelivr.net/gh/666WXY666/cdn/img/wallpaper/abstract/00E0F0ED-9F1C-407A-9AA6-545649D919F4.jpeg","https://cdn.jsdelivr.net/gh/666WXY666/cdn/img/wallpaper/abstract/67239FBB-E15D-4F4F-8EE8-0F1C9F3C4E7C.jpeg","https://cdn.jsdelivr.net/gh/666WXY666/cdn/img/wallpaper/abstract/B951AE18-D431-417F-B3FE-A382403FF21B.jpeg","https://cdn.jsdelivr.net/gh/666WXY666/cdn/img/wallpaper/abstract/2884F904-F1F3-479E-AE27-5EBC291B63B0.jpeg"];!function(t){for(var a=t.length;a--;){var e=Math.floor(Math.random()*a),p=t[e];t[e]=t[a],t[a]=p}}(t),$.backstretch(t,{duration:"20000",fade:"1500"})})</script><script src="https://cdn.jsdelivr.net/npm/aplayer@1.10/dist/APlayer.min.js"></script><script src="https://cdn.jsdelivr.net/npm/meting@2.0/dist/Meting.min.js"></script><script src="https://cdn.jsdelivr.net/npm/valine@1.4/dist/Valine.min.js"></script><script>var GUEST_INFO=["nick","mail","link"],meta="nick,mail,link".split(",").filter(function(i){return-1<GUEST_INFO.indexOf(i)}),REQUIRED_FIELDS=["nick","mail","link"],requiredFields="nick,mail".split(",").filter(function(i){return-1<REQUIRED_FIELDS.indexOf(i)}),valine=new Valine;function emoji(i,e,a){return i+"/"+i+"-"+e+"."+a}for(var emojiMaps={},i=1;i<=54;i++)emojiMaps["tieba-"+i]=emoji("tieba",i,"png");for(i=1;i<=101;i++)emojiMaps["qq-"+i]=emoji("qq",i,"gif");for(i=1;i<=116;i++)emojiMaps["aru-"+i]=emoji("aru",i,"gif");for(i=1;i<=125;i++)emojiMaps["twemoji-"+i]=emoji("twemoji",i,"png");for(i=1;i<=4;i++)emojiMaps["weibo-"+i]=emoji("weibo",i,"png");valine.init({el:"#valine_container",meta:meta,appId:"NM0ViQjTChbCUYqHomzuJjPT-gzGzoHsz",appKey:"VvkTdJBscrl6AEDdfTc9f62b",placeholder:"快来评论吧~",pageSize:"10",avatar:"robohash",lang:"zh-cn",visitor:"true",highlight:"true",mathJax:"false",enableQQ:"true",requiredFields:requiredFields,emojiCDN:"https://cdn.jsdelivr.net/gh/xaoxuu/cdn-assets/emoji/valine/",emojiMaps:emojiMaps})</script><script src="https://cdn.jsdelivr.net/gh/666WXY666/cdn@8.8/js/app.js"></script><script src="https://cdn.jsdelivr.net/gh/xaoxuu/cdn-volantis@2.6.5/js/search.js"></script><script src="https://cdn.jsdelivr.net/gh/xaoxuu/cdn-volantis@2/js/comment_typing.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2/dist/clipboard.min.js"></script><script>function wait(callback, seconds) {
    var timelag = null;
    timelag = window.setTimeout(callback, seconds);
  }
  !function (e, t, a) {
    var initCopyCode = function(){
      var copyHtml = '';
      copyHtml += '<button class="btn-copy" data-clipboard-snippet="">';
      copyHtml += '<i class="fas fa-copy"></i><span>COPY</span>';
      copyHtml += '</button>';
      $(".highlight .code pre").before(copyHtml);
      $(".article pre code").before(copyHtml);
      var clipboard = new ClipboardJS('.btn-copy', {
        target: function(trigger) {
          return trigger.nextElementSibling;
        }
      });
      clipboard.on('success', function(e) {
        let $btn = $(e.trigger);
        $btn.addClass('copied');
        let $icon = $($btn.find('i'));
        $icon.removeClass('fa-copy');
        $icon.addClass('fa-check-circle');
        let $span = $($btn.find('span'));
        $span[0].innerText = 'COPIED';
        
        wait(function () { // 等待两秒钟后恢复
          $icon.removeClass('fa-check-circle');
          $icon.addClass('fa-copy');
          $span[0].innerText = 'COPY';
        }, 2000);
      });
      clipboard.on('error', function(e) {
        e.clearSelection();
        let $btn = $(e.trigger);
        $btn.addClass('copy-failed');
        let $icon = $($btn.find('i'));
        $icon.removeClass('fa-copy');
        $icon.addClass('fa-times-circle');
        let $span = $($btn.find('span'));
        $span[0].innerText = 'COPY FAILED';
        
        wait(function () { // 等待两秒钟后恢复
          $icon.removeClass('fa-times-circle');
          $icon.addClass('fa-copy');
          $span[0].innerText = 'COPY';
        }, 2000);
      });
    }
    initCopyCode();
  }(window, document);</script><script src="https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js"></script><script>function pjax_fancybox(){$(".article-entry").find("img").not(".inline").not("a img").each(function(){var t=document.createElement("a");$(t).attr("pjax-fancybox",""),$(t).attr("href",$(this).attr("src")),$(this).attr("data-original")&&$(t).attr("href",$(this).attr("data-original")),$(t).attr("data-fancybox","images");var a="";$(this).attr("alt")&&($(t).attr("data-caption",$(this).attr("alt")),a=$(this).attr("alt"));var e=document.createElement("div");$(e).addClass("fancybox"),$(this).wrap(e);var i=document.createElement("span");$(i).addClass("image-caption"),$(i).text(a),$(this).after(i),$(this).wrap(t)}),$(".article-entry").find("img").fancybox({selector:'[data-fancybox="images"]',hash:!1,loop:!1,closeClick:!0,helpers:{overlay:{closeClick:!0}},buttons:["zoom","close"]})}$(function(){pjax_fancybox()})</script><script>setLoadingBarProgress(100)</script><script>!function(e){var c=Array.prototype.slice.call(document.querySelectorAll("img[data-original]"));function i(){for(var r=0;r<c.length;r++)t=c[r],0<=(n=t.getBoundingClientRect()).bottom&&0<=n.left&&n.top<=(e.innerHeight||document.documentElement.clientHeight)&&function(){var t,n,e,i,o=c[r];t=o,n=function(){c=c.filter(function(t){return o!==t})},e=new Image,i=t.getAttribute("data-original"),e.onload=function(){t.src=i,n&&n()},e.src=i}();var t,n}i(),e.addEventListener("scroll",function(){var t,n;t=i,n=e,clearTimeout(t.tId),t.tId=setTimeout(function(){t.call(n)},500)})}(this);</script><script>window.addEventListener("load",function(){var t=/\.(gif|jpg|jpeg|tiff|png)$/i,r=/^data:image\/[a-z]+;base64,/;Array.prototype.slice.call(document.querySelectorAll("img[data-original]")).forEach(function(a){var e=a.parentNode;"A"===e.tagName&&(e.href.match(t)||e.href.match(r))&&(e.href=a.dataset.original)})});</script></body></html><script type="text/javascript" src="https://cdn.jsdelivr.net/gh/666WXY666/cdn@master/js/click_show_text.js"></script><canvas class="fireworks" style="position:fixed;left:0;top:0;z-index:1;pointer-events:none"></canvas><script type="text/javascript" src="//cdn.bootcss.com/animejs/2.2.0/anime.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/gh/666WXY666/cdn@master/js/fireworks.js"></script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome/css/font-awesome.min.css"><script src="https://cdn.jsdelivr.net/gh/666WXY666/cdn@master/live2d/autoload.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/gh/666WXY666/cdn@master/js/FunnyTitle.js"></script>